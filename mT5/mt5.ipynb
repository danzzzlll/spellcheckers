{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7119566,"sourceType":"datasetVersion","datasetId":4106253}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\ntqdm.pandas()\n\nfrom transformers import TextDataset\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\nfrom torch.nn.functional import cross_entropy\nfrom transformers import AutoModelForSeq2SeqLM, T5TokenizerFast, AdamW\n\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-05T17:59:37.583614Z","iopub.execute_input":"2023-12-05T17:59:37.583984Z","iopub.status.idle":"2023-12-05T17:59:50.482996Z","shell.execute_reply.started":"2023-12-05T17:59:37.583957Z","shell.execute_reply":"2023-12-05T17:59:50.482054Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# для отладки проблем с cuda\n# import os\n# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2023-12-05T17:59:34.678985Z","iopub.status.idle":"2023-12-05T17:59:34.679719Z","shell.execute_reply.started":"2023-12-05T17:59:34.679457Z","shell.execute_reply":"2023-12-05T17:59:34.679482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Первая часть данных, датасет с Rucode\ntrain = pd.read_csv('/kaggle/input/spell-check-dataset-rucode/train.csv', usecols=['corrupted_text', 'correct_text'])\n\ntrain = train.rename({'corrupted_text':'incorrect', 'correct_text':'correct'}, axis=1)\ntrain = train.sample(26000).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T17:59:50.484681Z","iopub.execute_input":"2023-12-05T17:59:50.485642Z","iopub.status.idle":"2023-12-05T17:59:57.439827Z","shell.execute_reply.started":"2023-12-05T17:59:50.485611Z","shell.execute_reply":"2023-12-05T17:59:57.438943Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dataset = load_dataset(\"ai-forever/spellcheck_benchmark\", \"RUSpellRU\", split='train[:]')\neval_dataset = load_dataset(\"ai-forever/spellcheck_benchmark\", \"RUSpellRU\", split='test[:]')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T17:59:57.441003Z","iopub.execute_input":"2023-12-05T17:59:57.441308Z","iopub.status.idle":"2023-12-05T18:00:00.108988Z","shell.execute_reply.started":"2023-12-05T17:59:57.441272Z","shell.execute_reply":"2023-12-05T18:00:00.108222Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d758c833d764865bad2d62b5ebb216e"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset russian_spellcheck_benchmark/RUSpellRU to /root/.cache/huggingface/datasets/ai-forever___russian_spellcheck_benchmark/RUSpellRU/0.0.1/87bfa2950c7b82ec565b4da426533874af24d25436ad08dba065a45895ad3945...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94c8ecdaedf1410aa76f9110c3821802"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.95M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f068a3b73e483a80a44426d19fe467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c75c3da3c6d54f2a98ede0722ee40462"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62d399f5ec624513b11b0a7d616702da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset russian_spellcheck_benchmark downloaded and prepared to /root/.cache/huggingface/datasets/ai-forever___russian_spellcheck_benchmark/RUSpellRU/0.0.1/87bfa2950c7b82ec565b4da426533874af24d25436ad08dba065a45895ad3945. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"first_df = pd.DataFrame({'incorrect':train_dataset['source'], 'correct': train_dataset['correction']})\nsecond_df = pd.DataFrame({'incorrect':eval_dataset['source'], 'correct': eval_dataset['correction']})\n\nfull_df = pd.concat([first_df, second_df, train])\nfull_df['incorrect'] = 'Spell correct: ' + full_df['incorrect']","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:00:00.110999Z","iopub.execute_input":"2023-12-05T18:00:00.111335Z","iopub.status.idle":"2023-12-05T18:00:00.150528Z","shell.execute_reply.started":"2023-12-05T18:00:00.111287Z","shell.execute_reply":"2023-12-05T18:00:00.149617Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"first_df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:56:36.976680Z","iopub.execute_input":"2023-12-05T18:56:36.977051Z","iopub.status.idle":"2023-12-05T18:56:36.988353Z","shell.execute_reply.started":"2023-12-05T18:56:36.977022Z","shell.execute_reply":"2023-12-05T18:56:36.987275Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                              incorrect  \\\n534                Как я понял, это изначально сделано.   \n823                   Я вам покажу, как будить Колдуна!   \n1198  Я думала, кстате, что даже у маленбких утят пе...   \n578   А в 8.30 я пошагала на пары, а вечером дописыв...   \n1285  Мужык был в транче и тихо повторял - \" меня в ...   \n\n                                                correct  \n534                  Как я понял это изначально сделано  \n823                     Я вам покажу как будить Колдуна  \n1198  Я думала кстати что даже у маленьких утят перь...  \n578   А в 8.30 я пошагала на пары а вечером дописыва...  \n1285  Мужик был в трансе и тихо повторял меня в горо...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>incorrect</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>534</th>\n      <td>Как я понял, это изначально сделано.</td>\n      <td>Как я понял это изначально сделано</td>\n    </tr>\n    <tr>\n      <th>823</th>\n      <td>Я вам покажу, как будить Колдуна!</td>\n      <td>Я вам покажу как будить Колдуна</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>Я думала, кстате, что даже у маленбких утят пе...</td>\n      <td>Я думала кстати что даже у маленьких утят перь...</td>\n    </tr>\n    <tr>\n      <th>578</th>\n      <td>А в 8.30 я пошагала на пары, а вечером дописыв...</td>\n      <td>А в 8.30 я пошагала на пары а вечером дописыва...</td>\n    </tr>\n    <tr>\n      <th>1285</th>\n      <td>Мужык был в транче и тихо повторял - \" меня в ...</td>\n      <td>Мужик был в трансе и тихо повторял меня в горо...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"MODEL_NAME = 'google/mt5-small'\ntokenizer = T5TokenizerFast.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:04:57.832082Z","iopub.execute_input":"2023-12-05T19:04:57.832488Z","iopub.status.idle":"2023-12-05T19:05:12.127240Z","shell.execute_reply.started":"2023-12-05T19:04:57.832460Z","shell.execute_reply":"2023-12-05T19:05:12.126253Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccf9da7d184d482dbaac548b7e21d7b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ff2d5d5f0344baf98e60b46e06e7ce9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b48ec834639483e99333fd842df5ac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8234a1ac8bb4407f971c2ee23276a0e5"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8edda0beeeec4e5ebd1f8ee5d3ae5375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2763bda26d540639734fc6274706a86"}},"metadata":{}}]},{"cell_type":"code","source":"class SpellCheckDataset(Dataset):\n    def __init__(self, df:pd.DataFrame):\n        self.inputs = df.iloc[:, 0].values\n        self.outputs = df.iloc[:, 1].values\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        input_text = self.inputs[idx]\n        output_text = self.outputs[idx]\n        return tokenizer(input_text, padding=False, truncation=True), tokenizer(output_text, padding=False, truncation=True)\n    \ndef collate_fn(batch):\n    input_texts = [item[0] for item in batch]\n    output_texts = [item[1] for item in batch]\n\n    input_texts = tokenizer.pad(input_texts, return_tensors=\"pt\", padding='longest')\n    output_texts = tokenizer.pad(output_texts, return_tensors=\"pt\", padding='longest')\n\n    return input_texts, output_texts\n\ndef bucketed_data_loader(dataframe: pd.DataFrame, batch_size:int):\n    dataframe = dataframe.copy()\n    dataframe['length'] = dataframe.iloc[:, 0].progress_apply(lambda x: len(tokenizer.encode(x, truncation=True)))\n    dataframe.sort_values(by='length', inplace=True)\n\n    dataset = SpellCheckDataset(dataframe.drop(columns=['length']))\n\n    sampler = torch.utils.data.BatchSampler(\n        torch.utils.data.SequentialSampler(dataset),\n        batch_size=batch_size,\n        drop_last=False\n    )\n\n    return DataLoader(dataset, batch_sampler=sampler, collate_fn=collate_fn)\n\nbatch_size = 8\nloader = bucketed_data_loader(full_df, batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:00:15.586777Z","iopub.execute_input":"2023-12-05T18:00:15.587105Z","iopub.status.idle":"2023-12-05T18:00:18.851287Z","shell.execute_reply.started":"2023-12-05T18:00:15.587077Z","shell.execute_reply":"2023-12-05T18:00:18.850131Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"  0%|          | 0/30008 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n100%|██████████| 30008/30008 [00:03<00:00, 9296.67it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:00:18.853079Z","iopub.execute_input":"2023-12-05T18:00:18.853633Z","iopub.status.idle":"2023-12-05T18:00:26.473955Z","shell.execute_reply.started":"2023-12-05T18:00:18.853589Z","shell.execute_reply":"2023-12-05T18:00:26.472925Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 40\nmodel.train()\n\nfor epoch in range(num_epochs):\n    for batch_idx, batch in tqdm(enumerate(loader)):\n        optimizer.zero_grad()\n\n        input_ids = batch[0][\"input_ids\"].to(device)\n        attention_mask = batch[0][\"attention_mask\"].to(device)\n        labels = batch[1][\"input_ids\"].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 240 == 9:\n            print(f\"Epoch: {epoch + 1}, Batch: {batch_idx}/{len(loader)}, Loss: {loss.item()}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:00:27.929826Z","iopub.execute_input":"2023-12-05T18:00:27.930230Z","iopub.status.idle":"2023-12-05T18:54:19.212917Z","shell.execute_reply.started":"2023-12-05T18:00:27.930198Z","shell.execute_reply":"2023-12-05T18:54:19.211627Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n11it [00:05,  5.48it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 9/3751, Loss: 1.9971446990966797\n","output_type":"stream"},{"name":"stderr","text":"251it [00:41,  6.70it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 249/3751, Loss: 0.43817901611328125\n","output_type":"stream"},{"name":"stderr","text":"491it [01:18,  6.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 489/3751, Loss: 0.4459899663925171\n","output_type":"stream"},{"name":"stderr","text":"731it [01:53,  6.79it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 729/3751, Loss: 0.9319515228271484\n","output_type":"stream"},{"name":"stderr","text":"971it [02:29,  6.75it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 969/3751, Loss: 0.5056430697441101\n","output_type":"stream"},{"name":"stderr","text":"1211it [03:05,  6.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 1209/3751, Loss: 0.3211566209793091\n","output_type":"stream"},{"name":"stderr","text":"1451it [03:41,  6.87it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 1449/3751, Loss: 0.45441192388534546\n","output_type":"stream"},{"name":"stderr","text":"1691it [04:16,  6.87it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 1689/3751, Loss: 0.2680402100086212\n","output_type":"stream"},{"name":"stderr","text":"1931it [04:52,  6.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 1929/3751, Loss: 0.20242580771446228\n","output_type":"stream"},{"name":"stderr","text":"2171it [05:28,  6.91it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 2169/3751, Loss: 0.39576393365859985\n","output_type":"stream"},{"name":"stderr","text":"2411it [06:03,  6.77it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 2409/3751, Loss: 0.5102012753486633\n","output_type":"stream"},{"name":"stderr","text":"2651it [06:39,  6.72it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 2649/3751, Loss: 0.30002525448799133\n","output_type":"stream"},{"name":"stderr","text":"2891it [07:14,  6.80it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 2889/3751, Loss: 0.5882150530815125\n","output_type":"stream"},{"name":"stderr","text":"3131it [07:50,  6.60it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 3129/3751, Loss: 0.3034571707248688\n","output_type":"stream"},{"name":"stderr","text":"3371it [08:26,  6.44it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 3369/3751, Loss: 0.3213995099067688\n","output_type":"stream"},{"name":"stderr","text":"3611it [09:04,  5.99it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 3609/3751, Loss: 0.0950116217136383\n","output_type":"stream"},{"name":"stderr","text":"3751it [09:32,  6.56it/s]\n11it [00:01,  6.76it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 9/3751, Loss: 0.4633176028728485\n","output_type":"stream"},{"name":"stderr","text":"251it [00:37,  6.64it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 249/3751, Loss: 0.28708985447883606\n","output_type":"stream"},{"name":"stderr","text":"491it [01:12,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 489/3751, Loss: 0.30857500433921814\n","output_type":"stream"},{"name":"stderr","text":"731it [01:48,  6.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 729/3751, Loss: 0.4761451482772827\n","output_type":"stream"},{"name":"stderr","text":"971it [02:24,  6.81it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 969/3751, Loss: 0.253158301115036\n","output_type":"stream"},{"name":"stderr","text":"1211it [02:59,  6.77it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 1209/3751, Loss: 0.07676158100366592\n","output_type":"stream"},{"name":"stderr","text":"1451it [03:35,  6.78it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 1449/3751, Loss: 0.21788163483142853\n","output_type":"stream"},{"name":"stderr","text":"1691it [04:11,  6.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 1689/3751, Loss: 0.16486069560050964\n","output_type":"stream"},{"name":"stderr","text":"1931it [04:47,  6.80it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 1929/3751, Loss: 0.092677041888237\n","output_type":"stream"},{"name":"stderr","text":"2171it [05:22,  6.90it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 2169/3751, Loss: 0.23089006543159485\n","output_type":"stream"},{"name":"stderr","text":"2411it [05:58,  6.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 2409/3751, Loss: 0.3159630298614502\n","output_type":"stream"},{"name":"stderr","text":"2651it [06:33,  6.74it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 2649/3751, Loss: 0.260448157787323\n","output_type":"stream"},{"name":"stderr","text":"2891it [07:09,  6.51it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 2889/3751, Loss: 0.3076982796192169\n","output_type":"stream"},{"name":"stderr","text":"3131it [07:45,  6.77it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 3129/3751, Loss: 0.12892726063728333\n","output_type":"stream"},{"name":"stderr","text":"3371it [08:21,  6.78it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 3369/3751, Loss: 0.1899082362651825\n","output_type":"stream"},{"name":"stderr","text":"3611it [08:58,  5.98it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 3609/3751, Loss: 0.05206269025802612\n","output_type":"stream"},{"name":"stderr","text":"3751it [09:26,  6.62it/s]\n11it [00:01,  6.89it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 9/3751, Loss: 0.13047991693019867\n","output_type":"stream"},{"name":"stderr","text":"251it [00:37,  6.88it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 249/3751, Loss: 0.19360317289829254\n","output_type":"stream"},{"name":"stderr","text":"491it [01:12,  6.86it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 489/3751, Loss: 0.2343810647726059\n","output_type":"stream"},{"name":"stderr","text":"731it [01:47,  6.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 729/3751, Loss: 0.21103784441947937\n","output_type":"stream"},{"name":"stderr","text":"971it [02:23,  6.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 969/3751, Loss: 0.15399006009101868\n","output_type":"stream"},{"name":"stderr","text":"1211it [02:58,  6.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 1209/3751, Loss: 0.07900543510913849\n","output_type":"stream"},{"name":"stderr","text":"1451it [03:34,  6.91it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 1449/3751, Loss: 0.38898175954818726\n","output_type":"stream"},{"name":"stderr","text":"1691it [04:10,  6.43it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 1689/3751, Loss: 0.047756556421518326\n","output_type":"stream"},{"name":"stderr","text":"1931it [04:45,  6.88it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 1929/3751, Loss: 0.11855590343475342\n","output_type":"stream"},{"name":"stderr","text":"2171it [05:20,  6.87it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 2169/3751, Loss: 0.2142293006181717\n","output_type":"stream"},{"name":"stderr","text":"2411it [05:56,  6.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 2409/3751, Loss: 0.37622424960136414\n","output_type":"stream"},{"name":"stderr","text":"2651it [06:31,  6.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 2649/3751, Loss: 0.11150596290826797\n","output_type":"stream"},{"name":"stderr","text":"2891it [07:07,  6.52it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 2889/3751, Loss: 0.1761285364627838\n","output_type":"stream"},{"name":"stderr","text":"3131it [07:43,  6.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 3129/3751, Loss: 0.1598057895898819\n","output_type":"stream"},{"name":"stderr","text":"3371it [08:19,  6.69it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 3369/3751, Loss: 0.0985126942396164\n","output_type":"stream"},{"name":"stderr","text":"3611it [08:57,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 3609/3751, Loss: 0.05450660362839699\n","output_type":"stream"},{"name":"stderr","text":"3751it [09:24,  6.64it/s]\n11it [00:01,  6.78it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 9/3751, Loss: 0.10883665084838867\n","output_type":"stream"},{"name":"stderr","text":"251it [00:37,  6.86it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 249/3751, Loss: 0.08462006598711014\n","output_type":"stream"},{"name":"stderr","text":"491it [01:12,  6.76it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 489/3751, Loss: 0.07649488747119904\n","output_type":"stream"},{"name":"stderr","text":"731it [01:48,  6.45it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 729/3751, Loss: 0.14134010672569275\n","output_type":"stream"},{"name":"stderr","text":"971it [02:23,  6.90it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 969/3751, Loss: 0.037552446126937866\n","output_type":"stream"},{"name":"stderr","text":"1211it [02:59,  6.88it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 1209/3751, Loss: 0.05176844820380211\n","output_type":"stream"},{"name":"stderr","text":"1451it [03:34,  6.54it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 1449/3751, Loss: 0.13337944447994232\n","output_type":"stream"},{"name":"stderr","text":"1691it [04:10,  6.64it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 1689/3751, Loss: 0.015207069925963879\n","output_type":"stream"},{"name":"stderr","text":"1931it [04:45,  6.73it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 1929/3751, Loss: 0.03202793374657631\n","output_type":"stream"},{"name":"stderr","text":"2171it [05:21,  6.61it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 2169/3751, Loss: 0.052407391369342804\n","output_type":"stream"},{"name":"stderr","text":"2411it [05:57,  6.50it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 2409/3751, Loss: 0.1362016499042511\n","output_type":"stream"},{"name":"stderr","text":"2651it [06:32,  6.71it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 2649/3751, Loss: 0.0790378674864769\n","output_type":"stream"},{"name":"stderr","text":"2891it [07:08,  6.71it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 2889/3751, Loss: 0.13644085824489594\n","output_type":"stream"},{"name":"stderr","text":"3131it [07:43,  6.74it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 3129/3751, Loss: 0.029689496383070946\n","output_type":"stream"},{"name":"stderr","text":"3371it [08:20,  6.78it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 3369/3751, Loss: 0.09692831337451935\n","output_type":"stream"},{"name":"stderr","text":"3611it [08:57,  5.97it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 3609/3751, Loss: 0.024262862280011177\n","output_type":"stream"},{"name":"stderr","text":"3751it [09:25,  6.64it/s]\n11it [00:01,  6.87it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 9/3751, Loss: 0.09621081501245499\n","output_type":"stream"},{"name":"stderr","text":"251it [00:37,  6.91it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 249/3751, Loss: 0.016371937468647957\n","output_type":"stream"},{"name":"stderr","text":"491it [01:12,  6.70it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 489/3751, Loss: 0.06699804961681366\n","output_type":"stream"},{"name":"stderr","text":"731it [01:47,  6.92it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 729/3751, Loss: 0.10688319802284241\n","output_type":"stream"},{"name":"stderr","text":"971it [02:23,  6.82it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 969/3751, Loss: 0.0270080529153347\n","output_type":"stream"},{"name":"stderr","text":"1211it [02:58,  6.98it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 1209/3751, Loss: 0.016049183905124664\n","output_type":"stream"},{"name":"stderr","text":"1451it [03:33,  6.92it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 1449/3751, Loss: 0.1178140789270401\n","output_type":"stream"},{"name":"stderr","text":"1691it [04:09,  6.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 1689/3751, Loss: 0.06646321713924408\n","output_type":"stream"},{"name":"stderr","text":"1931it [04:45,  6.79it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 1929/3751, Loss: 0.041152823716402054\n","output_type":"stream"},{"name":"stderr","text":"2171it [05:20,  6.32it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 2169/3751, Loss: 0.05096874758601189\n","output_type":"stream"},{"name":"stderr","text":"2411it [05:56,  6.80it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 2409/3751, Loss: 0.15410064160823822\n","output_type":"stream"},{"name":"stderr","text":"2651it [06:31,  6.82it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 2649/3751, Loss: 0.10466513782739639\n","output_type":"stream"},{"name":"stderr","text":"2891it [07:07,  6.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 2889/3751, Loss: 0.03456886485219002\n","output_type":"stream"},{"name":"stderr","text":"3131it [07:43,  6.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 3129/3751, Loss: 0.11810452491044998\n","output_type":"stream"},{"name":"stderr","text":"3371it [08:19,  6.72it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 3369/3751, Loss: 0.07819945365190506\n","output_type":"stream"},{"name":"stderr","text":"3611it [08:56,  6.02it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 3609/3751, Loss: 0.021809043362736702\n","output_type":"stream"},{"name":"stderr","text":"3751it [09:24,  6.64it/s]\n11it [00:01,  6.93it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 9/3751, Loss: 0.06406961381435394\n","output_type":"stream"},{"name":"stderr","text":"251it [00:37,  6.60it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 249/3751, Loss: 0.009546487592160702\n","output_type":"stream"},{"name":"stderr","text":"491it [01:12,  6.72it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 489/3751, Loss: 0.011705342680215836\n","output_type":"stream"},{"name":"stderr","text":"731it [01:47,  6.73it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 729/3751, Loss: 0.027988741174340248\n","output_type":"stream"},{"name":"stderr","text":"971it [02:23,  6.89it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 969/3751, Loss: 0.010717462748289108\n","output_type":"stream"},{"name":"stderr","text":"1211it [02:58,  6.98it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 1209/3751, Loss: 0.012508644722402096\n","output_type":"stream"},{"name":"stderr","text":"1451it [03:34,  6.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 1449/3751, Loss: 0.025888115167617798\n","output_type":"stream"},{"name":"stderr","text":"1691it [04:09,  6.87it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 1689/3751, Loss: 0.0593896247446537\n","output_type":"stream"},{"name":"stderr","text":"1931it [04:44,  6.78it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 1929/3751, Loss: 0.1704317182302475\n","output_type":"stream"},{"name":"stderr","text":"2171it [05:19,  6.93it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 2169/3751, Loss: 0.01649695821106434\n","output_type":"stream"},{"name":"stderr","text":"2411it [05:55,  6.76it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 2409/3751, Loss: 0.1172742173075676\n","output_type":"stream"},{"name":"stderr","text":"2651it [06:30,  6.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 2649/3751, Loss: 0.03495532646775246\n","output_type":"stream"},{"name":"stderr","text":"2697it [06:37,  6.78it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(loader)):\n\u001b[0;32m----> 6\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:461\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 461\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# model inference","metadata":{}},{"cell_type":"code","source":"def restore_punctuation(original_text, good_text):\n    res = []\n    punctuation = '''!@#$%^&*(){}[]|._`/?:;\"'\\,~'''\n    for orig_word, word in zip(original_text.split(), good_text.split()):\n        if orig_word[-1] in punctuation:\n            word = word + orig_word[-1]\n        if orig_word[0] in punctuation:\n            word = orig_word[0] + word\n\n        if (orig_word == '-' or orig_word == '—') and word == 'я':\n            word = orig_word\n\n        if orig_word.istitle():\n            word = word.capitalize()\n\n        res.append(word)\n\n    restored_text = ' '.join(res)\n    for punct in punctuation:\n        restored_text = restored_text.replace(' ' + punct, punct)\n\n    return restored_text","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:54:23.603536Z","iopub.execute_input":"2023-12-05T18:54:23.604580Z","iopub.status.idle":"2023-12-05T18:54:23.611844Z","shell.execute_reply.started":"2023-12-05T18:54:23.604551Z","shell.execute_reply":"2023-12-05T18:54:23.610925Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"prefix = 'Spell correct: '\ninput_text = 'Молако! Надя решила прикинутся мервтой'\ninput_ids = tokenizer.encode(prefix+input_text, return_tensors='pt')\n\ninput_ids = input_ids.to(device)\n\nwith torch.no_grad():\n    outputs = model.generate(input_ids)\n\noutput_text = tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:03:13.716056Z","iopub.execute_input":"2023-12-05T19:03:13.716458Z","iopub.status.idle":"2023-12-05T19:03:13.948549Z","shell.execute_reply.started":"2023-12-05T19:03:13.716425Z","shell.execute_reply":"2023-12-05T19:03:13.947738Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, HTML\n\n# для подкрашивания измененных слов в получившемся тексте\ndef highlight_corrections(original_text, corrected_text):\n    original_words = original_text.split()\n    corrected_words = corrected_text.split()\n\n    def create_highlighted_html(words, corrections):\n        highlighted_html = \"\"\n        for word, is_corrected in zip(words, corrections):\n            if is_corrected:\n                highlighted_html += f\"<mark>{word}</mark> \"\n            else:\n                highlighted_html += word + \" \"\n        return highlighted_html\n\n    corrections = [ow != cw for ow, cw in zip(original_words, corrected_words)]\n    highlighted_original = create_highlighted_html(original_words, corrections)\n    highlighted_corrected = create_highlighted_html(corrected_words, corrections)\n\n    display(HTML(f\"Оригинальный текст: {highlighted_original}<br><br>Исправленный текст: {highlighted_corrected}\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:03:14.291112Z","iopub.execute_input":"2023-12-05T19:03:14.291763Z","iopub.status.idle":"2023-12-05T19:03:14.299080Z","shell.execute_reply.started":"2023-12-05T19:03:14.291729Z","shell.execute_reply":"2023-12-05T19:03:14.298142Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"highlight_corrections(input_text, restore_punctuation(input_text, output_text))","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:03:14.620639Z","iopub.execute_input":"2023-12-05T19:03:14.621527Z","iopub.status.idle":"2023-12-05T19:03:14.628092Z","shell.execute_reply.started":"2023-12-05T19:03:14.621485Z","shell.execute_reply":"2023-12-05T19:03:14.627329Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Оригинальный текст: <mark>Молако!</mark> Надя решила прикинутся <mark>мервтой</mark> <br><br>Исправленный текст: <mark>Молоко!!</mark> Надя решила прикинутся <mark>мертвой</mark> "},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}